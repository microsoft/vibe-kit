# BioEmu Explorer Environment Configuration
# Copy this file to .env and fill in your actual values

# Flask Configuration
FLASK_PORT=5000
FLASK_DEBUG=1

# ============================================================
# BioEmu Mode Selection
# ============================================================
# Choose ONE mode: 'azure' (cloud) or 'local' (GPU)
# 
# - azure: Uses Azure AI Foundry endpoint (fast, pay-per-use)
# - local: Runs BioEmu on your local GPU (requires setup below)
#
BIOEMU_MODE=azure

# ============================================================
# Option A: Azure BioEmu Configuration (BIOEMU_MODE=azure)
# ============================================================
# Required when BIOEMU_MODE=azure
AZURE_BIOEMU_ENDPOINT=https://your-bioemu-endpoint.inference.ml.azure.com/score
AZURE_BIOEMU_KEY=your_azure_bioemu_api_key_here

# ============================================================
# Option B: Local BioEmu Configuration (BIOEMU_MODE=local)
# ============================================================
# Requirements for local mode:
#   - Linux OS only (not Windows, not macOS)
#   - Python 3.10 or 3.11 (NOT 3.12 - ColabFold compatibility issues)
#   - GPU (CUDA) strongly recommended; CPU works but very slow
#   - pip install bioemu torch
#
# Known Issues:
#   - Python 3.12: ColabFold 1.5.4 fails to build pandas dependency
#   - Dev containers: May have /tmp space issues for ColabFold install
#   - First run: Downloads ~7GB (model checkpoint + ColabFold)
#
# Performance (A100 GPU, 1000 samples):
#   - 20 residues: ~2 min
#   - 100 residues: ~15 min
#   - 300 residues: ~45 min
#   - CPU: 10-100x slower
#
# No additional env vars needed for local mode - just set BIOEMU_MODE=local

# ============================================================
# AI Copilot Configuration (Optional)
# ============================================================
# Choose ONE: GitHub Models or Azure OpenAI

# Option 1: GitHub Models (free with GitHub PAT)
# Get a PAT from: https://github.com/settings/tokens
# Required scope: None (public models access)
GITHUB_TOKEN=
GITHUB_MODEL=gpt-4o

# Option 2: Azure OpenAI
# AZURE_OPENAI_API_KEY=your_azure_openai_api_key_here
# AZURE_OPENAI_ENDPOINT=https://your-resource-name.cognitiveservices.azure.com/
# AZURE_OPENAI_API_VERSION=2025-01-01-preview
# AZURE_OPENAI_DEPLOYMENT_NAME=gpt-4o-mini
